{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=1)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAH4FJREFUeJztnVuMXNd1pv9Vt67qezf7wlaTEiWK\n0ki2JUqhBY0UGLI9EyhGENlAEtgPhh6MMBjEwBjIPAgeYOwB5sEejG34YeABPVKiDDy+xJexEAiT\nCIIDIXEgm7Jl6kJLoihKvLSaTXY3u6uruq5rHro0oVr73yzxUk1p/x9AsHqv2ufss+usc+rsv9Za\n5u4QQqRHZqsHIITYGuT8QiSKnF+IRJHzC5Eocn4hEkXOL0SiyPmFSBQ5vxCJIucXIlFyl9LZzO4H\n8E0AWQD/092/Ent/Pp/3vmIxaGu1mnw/pD3HDAAKOX5dy0dsuWyWj8PCOzSLXEMjY2w2W9QW+91l\nNjZG8ovNtrf5vtp8b5aJHECEdjt8bLGxR7cXGb9FJpnZMpFxZDP882TnAAC0I7+W9diJwPpEtxdm\ncXkV5cp6Vzu7aOc3syyA/w7g3wI4AeCXZvaYu7/I+vQVi7j9jjuDtuXlRbqvvkz4g99W4JNz7UQ/\ntU2OD1DbxOgQtRWy+WB7rq9E+yDLp3hxaZna6k1+bGOjI9SWaTWC7bVajfZZX1+ntmIpfLEGgBb4\nxatSLQfbR0aHaR843169Vqe2LMKfC8AvNkODg7TPwAA/P/J5Ph/VyBg9doPIhM+R2DE3PezfX334\nR3w/m3fb9TvfyV0Ajrj7UXevA/gegAcuYXtCiB5yKc4/C+D4eX+f6LQJId4DXMozf+h7xzu+q5rZ\nfgD7AaDQ13cJuxNCXE4u5c5/AsDO8/7eAeDU5je5+wF33+fu+/J5/mwmhOgtl+L8vwSwx8yuN7MC\ngE8DeOzyDEsIcaW56K/97t40s88D+DtsSH2PuPsLsT7r1SpeeDH8lnNnz9J+Y+Rpwbbxx4iJFl+1\nt9IUta21uepQboVX4N0KtE9lna/YVqp8Bb7R4tLWmSxXcoq58BibTb69LFltBoC+yKNaZX2N2prt\n8HHb+jbaJxNRARsRtaKU4yvwZbJivhiRlvv7+Wq/Zfi3VyNqEAAgIh9W1sMKTbMRbgeAbC78uTTW\nq3wMm7gknd/dHwfw+KVsQwixNegXfkIkipxfiESR8wuRKHJ+IRJFzi9EolzSav+7xcxQYqF4XC3D\ndUTSu36aB7hMTY1TWykm5USitqq1cADMeoPLUB7ZXqEUCQiKBPZ4m+9vZDwc0NRs8O0V8nwcLR5r\ng2yBy4C1eniuGk0+H/2R7eUG+BiLkX5NC8uRmUiUYDMSgRdRWTEYCQgqr3FZtNEMS3qxgMrVlXPB\n9nbsA9u8/a7fKYR4XyHnFyJR5PxCJIqcX4hEkfMLkSg9Xe3PwFG0cEDF0BCP6rh5dizYvq3E++Tb\nPDVVeZEH27Ta/HpYXQuPPRNJUzA8ytNF5SKr1MvnVnm/yKc2PhRe7V9d4avN9UiATpUEnQDxvHRs\n5btR54EnmRY/sHwkwKhFUpcBQI4sz9dqvE8hz6WnTJsHBNXKPCgMJCgMAPrIadxsc0XiXDms+LQi\nfTajO78QiSLnFyJR5PxCJIqcX4hEkfMLkShyfiESpadSXzZjGOsL77IUkXJGBsNBHZPDPGdai5SL\nAhCpMwNkc5FEciQPW60dkZoiulwuElzSqnFJzLP8mn36dLgKUKvBj3q1UqG2SovLooOlSPWdGinX\nBX7MGeNyWDZSFam6xueqPx8O/spFSmGtR/IuVhtc6mtHiqwtl7n0vLwWPn/KFb6v9Ub4HKhHcjVu\nRnd+IRJFzi9Eosj5hUgUOb8QiSLnFyJR5PxCJMolSX1mdgzAKjbUs6a774u9P581TI2GSysN5bnE\nViyGbZksl1ZKkfx4jSaXvdqRSDX3sARUj+Tba9W5DNj2SMRcRGLzHI86W62HI/RaLT6/lUhpsFiZ\nr9UyH//JWngc+Qzf3nCZz33jzQVqqy5zqfLayT3B9qmpncF2ALChcH48AKgtnaG2cplHR55b4VLf\nmXNhqfK14yu0Tysb/jxr9e5z+F0Onf+j7s5nRAhxVaKv/UIkyqU6vwP4ezN7xsz2X44BCSF6w6V+\n7b/X3U+Z2RSAJ8zst+7+1Plv6FwU9gNAMfJcL4ToLZd053f3U53/TwP4CYC7Au854O773H1fIaen\nDCGuFi7aG81swMyG3noN4PcAPH+5BiaEuLJcytf+aQA/6ZS3ygH43+7+f2Md8rkMrpkKJ3YcLvAI\npsH+sLRlEakMkQgri0TT1apcNsoQGXDbEC8bNjAQljYBYOUcF0lGhnnE3GokqebrJ8LbLNf4I1ch\nEgg22x+JSszzaLpjZ8PRheseSboaieobHR6itns+8GFqW5kLS19e4fsameDRorUKn49ymd9L+/J8\nmzu3h49tamqa9pkn0uHiK2/SPpu5aOd396MAbr/Y/kKIrUUP4UIkipxfiESR8wuRKHJ+IRJFzi9E\novQ0gWcum8H4UDjaLlcPS0MA0JcPD7O/L1yXDgBqVS6HNSL11kZHw3UBAcBJ0sd6i19DGw0ezdU/\nyOv4nVoI12IDgFeP8aiz06vhY4vkgsSuSM3DT37kDmrbMcPH/8NnXg22/3NEimq2eSRjLsOludXl\n09RWWQ3P49AQl97Q4tGFxSLvVyDRpwDQb7xfsxX+cK695hraZ2gxXMvx0LHuY+x05xciUeT8QiSK\nnF+IRJHzC5Eocn4hEqW3q/25HKbGJ4K26iJfFc9YeJjlCl/Rr9b58nbOIvnsImWt2JWy2uCr1KNj\nPECn3uIr2EePn6K2syt8jCy/XzZS4mu4yLc3leN55IqRz2zP8EywfW6cj2M+smpfq/A5/vVLL1Nb\nhuQgbAxGSo2N8IAaZLjLjIxw9WmoHSkPRvI8ep3P/a7JcIBcX777+7nu/EIkipxfiESR8wuRKHJ+\nIRJFzi9Eosj5hUiUHkt9eYxNTAZtY4O8vFYmEw6KWF5Zon0aa+HABwDItGLlunhCOycBRoODPE9f\nA/y4Dr/6ErWVSbkrACgW+6itVAiPsTTAZaixLJdFnzkyT23NOj99aiPbg+2T43yuDFx+azS5rFip\n81yCayRXX73Bj9ki0m2kmhvymUipt0wkd2EuPI/NGg/uciITs+CzELrzC5Eocn4hEkXOL0SiyPmF\nSBQ5vxCJIucXIlEuKPWZ2SMA/gDAaXf/YKdtHMD3AewCcAzAn7g7193+ZWsAke0sUs6I0RfJp9YP\nnl8uF7nmZTKRfHxEBuwr8XJdZ97kkmPlDJ+y3RFJrMZVLxSJpHfzjbO0TyaywWaWz/FKRGrNZcN5\nBocK4Wg0ANg2diO17d5zLbW99sYvqO23L50MthfyERnNy9TWbHKXyZCISgDIF/g8ttvh86od0RXN\nwuepxbTITXRz5/8rAPdvansIwJPuvgfAk52/hRDvIS7o/O7+FIDFTc0PAHi08/pRAJ+8zOMSQlxh\nLvaZf9rd5wCg8//U5RuSEKIXXPEFPzPbb2YHzezgaiXysCqE6CkX6/zzZjYDAJ3/af4ldz/g7vvc\nfd9QP1/EEkL0lot1/scAPNh5/SCAn16e4QghekU3Ut93AdwHYMLMTgD4EoCvAPiBmX0OwBsA/rib\nnbXdUV0PJyu0Bo/MAsIRWGtrvGxVvcGva80Mj7QrV3jSxJVKWLab3cmn0Zt8e9dNcFlm9yyXhirr\nvN/sTXuD7QXnj1xL53gi1NJoOOEqAOAsj1TbuT1camp5jUcr3vCv9lDb8BiPShweu5XalhbCn9nS\nMj938hE5MuM8orLRjkSL8mBRtEiEYSRIkEbvdR/T14Xzu/tniOnj72I/QoirDP3CT4hEkfMLkShy\nfiESRc4vRKLI+YVIlJ4m8HQ4WhaWQ7zFEyoyWaNU5PLP4BC3nVrgsuJrxxeoLZcPj6MwH44cA4D1\nN/n29kxzOe/j93HZ69WTm0Mt/oWh2XCC1Ilt4YSaAHB6gSfpHB2NyF5tPv4CSVh5eoHPVa64TG0L\ny3PUdnKOR+Hl8+HzYHSEa2/VKhfMPMfvlxbR5toRGTBj4X4WiTCNlHnsGt35hUgUOb8QiSLnFyJR\n5PxCJIqcX4hEkfMLkSg9lfqy2QxGR8OJNZs5LvWVy+GING9w+eTcKpeNXn+dS1vlMpeNSsXwtXLu\nKI/cmy7ypI6zs9dR2+g1N1BbfjUSIkaSmu64/S7e5U0uv5WaXKpsgUcKrq2FbTP9YSkSAOotflw2\nwBOy7hgIRxACwNBoWOJcPfsm7XN6/gy1NYx/nuv1SLKaDNfmBvrCeS7q1YiESRKCGpENg0Pq+p1C\niPcVcn4hEkXOL0SiyPmFSBQ5vxCJ0tPV/naridXls+GB1HlZqzwpTQSeQg65LDdWyjx/29gQD2QZ\nHQyvylYX+Wr/1Ow2apu97T5qe/5EndpePsJt98yMB9uXl3mf6d23U1sGFWqr17gSMOrhlfuV0+HP\nHwBKdZ5LcGY8fFwAsNziefXyt40F26uRQKF/evwxajtxnCaqRjZSkguRMlosjqgRKyvXCM8VC4IL\nbqPrdwoh3lfI+YVIFDm/EIki5xciUeT8QiSKnF+IROmmXNcjAP4AwGl3/2Cn7csA/hTAW1rPF939\n8W52mCWKR6vKpT4nMkmGlPECgJZxqW+RK0rIrUTyt9XCctlMJM/dhz/6MWrbcfPd1Pbjv3yE2rZH\nglyy9XB+wpNHX+Xbu4GXuypuu5HaBpx/ZpXFsCRWaoelNwCoV7mseGaV20Ynr6e2bdt3Bdur5WHa\nJ8NNaBV48E4sh1+jwaVWa4YD1Mx54FqzGXbdyy31/RWA+wPt33D3vZ1/XTm+EOLq4YLO7+5PAeDp\nYoUQ70ku5Zn/82Z2yMweMTP+XU4IcVVysc7/LQC7AewFMAfga+yNZrbfzA6a2cFyhT/3CCF6y0U5\nv7vPu3vL3dsAvg2Apolx9wPuvs/d9w328ywoQojeclHOb2Yz5/35KQDPX57hCCF6RTdS33cB3Adg\nwsxOAPgSgPvMbC8AB3AMwJ91szMDYESJaJEoJYCXLYpUToJX+fYykRR449t4ma/tA2Fp8c59N9M+\nt9zD5byl0zxHW1+T5yC8YcdOamtb+OC2T/Hcec11LplWItGA9Sbv16iGT60WuEz56skT1Pbc8wep\n7Z67+Ri3bQ9HVa6s8ug8UuELADCxi8u67Vh5rXpEtiMS8rkFfg7UVsODbEfkwc1c0Pnd/TOB5oe7\n3oMQ4qpEv/ATIlHk/EIkipxfiESR8wuRKHJ+IRKlpwk83YE2iWCq1rj+ViBRbLkc/9FQNlOjthtn\n+K+RiyV+Pdx13bXB9tt/96O0z8zNt1Hbs//8l9R27U6esHL7Bz5EbYXJ3cH2XP8I7VNZ55JjdYVH\n7s2fOk5tS/Nh2a7V4NF5paFwglQAmJjgyTGPn/o1tU3PzAbbmxV+zF7l546tLVFby8MRlQDgTOMG\nUOoLH1thOz/mlT4S6ZpTuS4hxAWQ8wuRKHJ+IRJFzi9Eosj5hUgUOb8QidJTqc/MkM+Gd7kUSdDY\nWg/LF6X+Eu2TzXBpZSoSuXf8FI+k2v2pUCpDYMeHwu0bcFmxsbpGbSNDXJqbvGkvta3lwhLhC7/+\nJe1Tq/JxrKzw+Thz8g1qy7bCkWrFIj/lZq8Py3IAcNtNPJFoM8sj7fLZ0XB7gUd95ta5ZFd5/SS1\nMRkbAJqR22yZ1JXs38aPa/qacLRiPt/9/Vx3fiESRc4vRKLI+YVIFDm/EIki5xciUXob2NNuo1YN\nlzvq7+NDsWJ4NTSf4TnkvMVtpUFeyusPP/0Atd3z+x8Ptg9PTNM+80cPU1s2Mv7l1XPUtnDsJWo7\ntRpecf6H//MT2mewxANI1ms8AGb7NFckhofCwVivneAKQT0yH+PX7KK2mz70O9SGVl+weXGZ5wus\nrPN74lKVj9Gcn8PrVR64ViYltrzMS4PdEhYx0O6+Wpfu/EKkipxfiESR8wuRKHJ+IRJFzi9Eosj5\nhUiUbsp17QTw1wC2A2gDOODu3zSzcQDfB7ALGyW7/sTdeYIzAA5H20lppTYPirBmWCZpeqTEVyRn\nWrFvmNr2/g6XjfryYUnsxWd5DrmlU69SW63GpZzVpbPUdvzIi9RW9nCwU77F9zWY49LncJEHl0yO\nEb0JwNz8XLC9GSnLVlnlsuLx17hECLxALeVyOAdhMcfPj2bfFLWdbfJzp1TiOQj7h3gQWikXliNX\nKyu0T7Mdlhwd3Wt93dz5mwD+wt1vAXA3gD83s1sBPATgSXffA+DJzt9CiPcIF3R+d59z9191Xq8C\nOAxgFsADAB7tvO1RAJ+8UoMUQlx+3tUzv5ntAnAHgKcBTLv7HLBxgQDAvysJIa46unZ+MxsE8CMA\nX3B3/jDyzn77zeygmR1cq/JSykKI3tKV85tZHhuO/x13/3Gned7MZjr2GQDBgufufsDd97n7voES\nL7IhhOgtF3R+MzMADwM47O5fP8/0GIAHO68fBPDTyz88IcSVopuovnsBfBbAc2b2bKftiwC+AuAH\nZvY5AG8A+OMLb8qxoRa+k3aTPxLk8uGce61IzrQ6ePTV9AgvhfV3j/0ttY1PhyWlqZmdfBwVHp2X\nz4clHgAYHOARc7kMl+YGiBy5fWqC9qmuLlJbKcvHeHZhgdoa9fBnM1TkkledyHIA8EokB+Hcb1+m\ntlqT5OPL8zlsxeZ3B5c+McDP4Uwfl1qLRLYbA5+rWz5wQ7C9VHyN9tnMBZ3f3f8RACsAFo5xFUJc\n9egXfkIkipxfiESR8wuRKHJ+IRJFzi9EovQ0gSfc0G6HhYNCJLKsmCPJDzNMhAA8UsKpXeeRZWfO\nhKPRAKC8ELaVGh/k+wI/rvGxcMklABi9ZpLamq0atZ089WawPRbtlcnw06De5JJp1njiz4FiWJ4l\nAZob24sZI1GarTovKZYh59tKhUcQ1vt4ua6ha/jcr5X4OFbbXAZcXwvfg7cNh+U8AJiYCp87uXz3\nLq07vxCJIucXIlHk/EIkipxfiESR8wuRKHJ+IRKlt1IfDBkLR4kV+3gEk5MIvYFSWE4CgIEhLpVV\nGjzCatsQzzmQI+Oon5unfdoZvr1Knktb09PX823WuWx08207gu0//9mTtE/d16gtb1xOrZYr1DY8\nFE50WchxeTBrPEqzvM4/s9fmeN7Y5aXwZ1YzfsyTN/N74uxoJCrR+We9dIbPVWE9PCcDs1wKrlbC\nc9WOqKWb0Z1fiESR8wuRKHJ+IRJFzi9Eosj5hUiUnq72Zwwo5MLXm0qNB0xkScmodiS/XKXBV1ez\neR4k0lfgCkI+Hx5HoZ/n2xsZ5gFGby5wlaAyG161B4CpnTdS28nTZ4LtH/jwvbRPeeEUtR19mZfC\nWivzQJZcNhwcMzLCV8SN5HcEgLmTfIxvHON5EjN94fkf3s4/58lxXpLLIqqDLfLPemyJu9rsVDin\n5I5RnhvyyIvhAK5alQetbUZ3fiESRc4vRKLI+YVIFDm/EIki5xciUeT8QiTKBaU+M9sJ4K8BbMdG\nra0D7v5NM/sygD8F8FbNpi+6++PRneUM05Ph603j7Fnar9oKS0BrPDYDnuFBIrkcP+zhYV7WqkBK\nYVXXeNHiUiynWp3bDv7859R2w81cIjxxIiwBZSL5Dvv7IsE2ETm1VOLS1lo5LPVVqzw/XjNSsm2w\nxMdxz503UVtxKCzDNrNcEmtFZOLqcS71ZVaL1DbVP0Rtd9wUzgE5NTpN+zwzdzTY3mzwnIub6Ubn\nbwL4C3f/lZkNAXjGzJ7o2L7h7v+t670JIa4auqnVNwdgrvN61cwOA5i90gMTQlxZ3tUzv5ntAnAH\ngKc7TZ83s0Nm9oiZjV3msQkhriBdO7+ZDQL4EYAvuPsKgG8B2A1gLza+GXyN9NtvZgfN7OBKhT/T\nCSF6S1fOb2Z5bDj+d9z9xwDg7vPu3nL3NoBvA7gr1NfdD7j7PnffN9zPf9cthOgtF3R+MzMADwM4\n7O5fP6995ry3fQrA85d/eEKIK0U3q/33AvgsgOfM7NlO2xcBfMbM9gJwAMcA/NmFNlQoGK7dGb77\njxiXSY4cD0sv8ws8Oq/e4tLQ4CA/7LUKj1RrtVeD7dnINXRxIRxlBwCrZS7LrDd4pFrW+RiHBsMR\nYvNvcin1xBqXr9rOJcLpSS6LWjsspS0tL9I+fQP8Mxsd4VJZIctLotXqZI5z/FvoWo3PR70cKVHW\n5ufBjTtnqO2a7eFcfcdPcEn37ELYJ5qxkmeb6Ga1/x8BhM6AqKYvhLi60S/8hEgUOb8QiSLnFyJR\n5PxCJIqcX4hE6WkCz2zOMDxGIuOIdAEAY1NEyhngSRjPzPOEoOuRcle5Ak/eyLq1GzyCsNHi4zhX\n5WWmBiJRbOsVLkVV1xeC7fXIGFsRmzuX0corPKxyeDj82QwP82Sn1So/B86c5XM1OMijCy0Tvr9Z\nk8vEhRwvydXHFWkUCnyudt24i9qqlfBYnnqKJ0899NLp8LbWu4/q051fiESR8wuRKHJ+IRJFzi9E\nosj5hUgUOb8QidJTqc/MkCuGd1kc5lFW44Pha1SuymW0fIlHN61E6qahxa+HpWI4oWIrz/fVqnGJ\nqtDPx5GPRJ1ls1zirHl4LPUGlzc9ErlnXBGD17nk2CKm2HGhwOXN5SU+j9U6T8Y5MhqWbnNEAgSA\nTC5SAxJcSps/E476BIClSATn6lo4gvOJn/2W74uooussijGA7vxCJIqcX4hEkfMLkShyfiESRc4v\nRKLI+YVIlJ5Kfe22ocwSIGYHab/BgbBulC9xHWogEn41MsKlufIKryVXXgnXwStXIlF969w2VAgn\nbgSAIqkLCADNGpc4c7nw9bwQuczn+3g0mhnv2B9JhJohpmaLy3KFEj/m4VEuby4ucoltlUifw+N8\n7itNPr+vHOOJUA8fOk5t0+M8WnR6B4lKzPDzdIIkND1d5vP7js13/U4hxPsKOb8QiSLnFyJR5PxC\nJIqcX4hEueBqv5kVATwFoK/z/h+6+5fM7HoA3wMwDuBXAD7r7tEyvPU6cOL1sK22zFfnhybDwQrF\nUiSgg4sHGB/nh11e43nklpfDtqWzPFhliS8OI9vmq+xt50pGq8UVBLTDtthV3jI8sCeb43NVjQRB\nOYkvyZMyXgDQrPBSXq1Ifr9WjqsEy+Vwv3pkChcjis9rr/APdPksH2N9je9w+8j2YPut183SPmyI\nR+a58rGZbu78NQAfc/fbsVGO+34zuxvAVwF8w933AFgC8Lmu9yqE2HIu6Py+QbnzZ77zzwF8DMAP\nO+2PAvjkFRmhEOKK0NUzv5llOxV6TwN4AsCrAJbd//+XuxMA+HcUIcRVR1fO7+4td98LYAeAuwDc\nEnpbqK+Z7Tezg2Z28FyZJ38QQvSWd7Xa7+7LAP4BwN0ARs3srdWgHQBOkT4H3H2fu+8bGYxUPBBC\n9JQLOr+ZTZrZaOd1CcC/AXAYwM8A/FHnbQ8C+OmVGqQQ4vLTTWDPDIBHzSyLjYvFD9z9b83sRQDf\nM7P/AuDXAB6+0IbccmjlJ4K2RuHDtF+tHQ60yDTP0D7FES5fjU7ybyBjGZ4DbbwSDrRYXuTlnZbP\ncDmvusanv9WM5Lpzfs1uN8NjXK/yR65CIZIvMMfHv7rOA0+q5BEvH1GDhzI8+KWdCee5A4BGg89j\n30BYMi3m+TkwWuCBPbsxSm237eVlw26+bS+17brxxmD7Xf+aS4cnTpWD7f90NKItb+KCzu/uhwDc\nEWg/io3nfyHEexD9wk+IRJHzC5Eocn4hEkXOL0SiyPmFSBTzSPTYZd+Z2QKAt+L6JgBwra53aBxv\nR+N4O++1cVzn7pPdbLCnzv+2HZsddPd9W7JzjUPj0Dj0tV+IVJHzC5EoW+n8B7Zw3+ejcbwdjePt\nvG/HsWXP/EKIrUVf+4VIlC1xfjO738xeMrMjZvbQVoyhM45jZvacmT1rZgd7uN9HzOy0mT1/Xtu4\nmT1hZq90/h/bonF82cxOdubkWTP7RA/GsdPMfmZmh83sBTP79532ns5JZBw9nRMzK5rZL8zsN51x\n/OdO+/Vm9nRnPr5vZpHQzy5w957+A5DFRhqwGwAUAPwGwK29HkdnLMcATGzBfj8C4E4Az5/X9l8B\nPNR5/RCAr27ROL4M4D/0eD5mANzZeT0E4GUAt/Z6TiLj6OmcADAAg53XeQBPYyOBzg8AfLrT/j8A\n/LtL2c9W3PnvAnDE3Y/6Rqrv7wF4YAvGsWW4+1MANuepfgAbiVCBHiVEJePoOe4+5+6/6rxexUay\nmFn0eE4i4+gpvsEVT5q7Fc4/C+D8cqZbmfzTAfy9mT1jZvu3aAxvMe3uc8DGSQhgagvH8nkzO9R5\nLLjijx/nY2a7sJE/4mls4ZxsGgfQ4znpRdLcrXD+UIqdrZIc7nX3OwH8PoA/N7OPbNE4ria+BWA3\nNmo0zAH4Wq92bGaDAH4E4AvuvtKr/XYxjp7PiV9C0txu2QrnPwFg53l/0+SfVxp3P9X5/zSAn2Br\nMxPNm9kMAHT+P70Vg3D3+c6J1wbwbfRoTswsjw2H+467/7jT3PM5CY1jq+aks+93nTS3W7bC+X8J\nYE9n5bIA4NMAHuv1IMxswMyG3noN4PcAPB/vdUV5DBuJUIEtTIj6lrN1+BR6MCdmZtjIAXnY3b9+\nnqmnc8LG0es56VnS3F6tYG5azfwENlZSXwXwH7doDDdgQ2n4DYAXejkOAN/FxtfHBja+CX0OwDYA\nTwJ4pfP/+BaN438BeA7AIWw430wPxvG72PgKewjAs51/n+j1nETG0dM5AXAbNpLiHsLGheY/nXfO\n/gLAEQB/A6DvUvajX/gJkSj6hZ8QiSLnFyJR5PxCJIqcX4hEkfMLkShyfiESRc4vRKLI+YVIlP8H\nIapt/5SJ3JoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "image, label = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(image))\n",
    "# print labels\n",
    "print(classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net) # show network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.0301,  0.0060, -0.0320,  0.0262, -0.0549],\n",
      "          [ 0.0177, -0.0353, -0.0144, -0.0627,  0.0175],\n",
      "          [-0.0631,  0.0238,  0.0491,  0.0210,  0.1054],\n",
      "          [-0.0304, -0.0043, -0.0141, -0.0418,  0.0379],\n",
      "          [-0.0335,  0.1044,  0.0790, -0.0786, -0.0771]],\n",
      "\n",
      "         [[-0.0322,  0.0880, -0.0890, -0.0656,  0.0824],\n",
      "          [-0.0258, -0.0863,  0.0691,  0.0699, -0.0044],\n",
      "          [-0.0643,  0.0678, -0.0304,  0.0733, -0.0054],\n",
      "          [ 0.1054,  0.0296,  0.0126,  0.0612, -0.1062],\n",
      "          [-0.0565,  0.0811,  0.0457,  0.0927, -0.0311]],\n",
      "\n",
      "         [[ 0.0436,  0.0341, -0.0226,  0.1134,  0.0790],\n",
      "          [ 0.0993, -0.0719,  0.0210, -0.0180,  0.0137],\n",
      "          [-0.0606,  0.0788, -0.0950,  0.0932,  0.0376],\n",
      "          [ 0.0090, -0.0347, -0.0051,  0.0551, -0.0575],\n",
      "          [ 0.0991,  0.0740, -0.0877,  0.0468, -0.0628]]],\n",
      "\n",
      "\n",
      "        [[[-0.0290,  0.0017, -0.0923,  0.0888, -0.0633],\n",
      "          [-0.0144, -0.0518,  0.0198, -0.0585,  0.0675],\n",
      "          [-0.0981, -0.1150, -0.0778, -0.0905,  0.0550],\n",
      "          [ 0.0910,  0.1136,  0.0593,  0.0283,  0.0489],\n",
      "          [ 0.0871, -0.0961, -0.0597,  0.0263, -0.0859]],\n",
      "\n",
      "         [[ 0.0215, -0.0246,  0.0642, -0.0819,  0.0735],\n",
      "          [-0.0328, -0.0855,  0.0469, -0.0105,  0.1061],\n",
      "          [-0.0668, -0.0448, -0.0258,  0.0456,  0.0001],\n",
      "          [-0.1108, -0.0033, -0.0099, -0.0684,  0.0497],\n",
      "          [ 0.0776, -0.0764,  0.0994, -0.0214, -0.0582]],\n",
      "\n",
      "         [[ 0.0023, -0.0830, -0.0710, -0.0849, -0.0052],\n",
      "          [-0.0983, -0.1133,  0.0889,  0.0267,  0.1104],\n",
      "          [-0.1059,  0.0178, -0.1029, -0.1022,  0.0405],\n",
      "          [-0.0968,  0.1066,  0.0078, -0.0507, -0.0698],\n",
      "          [-0.1124, -0.0189, -0.0855,  0.0806, -0.0160]]],\n",
      "\n",
      "\n",
      "        [[[-0.0322, -0.0456, -0.0453, -0.0896, -0.0259],\n",
      "          [ 0.0948,  0.0633, -0.0948,  0.0775, -0.0326],\n",
      "          [ 0.0070, -0.0429,  0.0955, -0.0121, -0.0547],\n",
      "          [-0.0994,  0.0343, -0.1008,  0.1139,  0.0142],\n",
      "          [ 0.0508, -0.0004, -0.0854,  0.0745, -0.0111]],\n",
      "\n",
      "         [[ 0.0774,  0.0173,  0.0598, -0.0530,  0.0669],\n",
      "          [-0.0668,  0.0330,  0.0243, -0.0977, -0.1027],\n",
      "          [ 0.1044,  0.0528,  0.1016, -0.0345, -0.1103],\n",
      "          [ 0.0752,  0.0639, -0.0963, -0.0108, -0.0342],\n",
      "          [-0.0092, -0.0496, -0.0305,  0.0274,  0.0176]],\n",
      "\n",
      "         [[-0.0712, -0.0391, -0.0967, -0.0683, -0.0188],\n",
      "          [ 0.0012, -0.0556, -0.0406, -0.0604,  0.0318],\n",
      "          [-0.0624,  0.0974,  0.0757, -0.0899, -0.0891],\n",
      "          [ 0.0591,  0.0404,  0.0303, -0.1102, -0.0505],\n",
      "          [-0.0779, -0.0174,  0.0852,  0.0731,  0.0174]]],\n",
      "\n",
      "\n",
      "        [[[-0.0300, -0.0895,  0.1029,  0.0646, -0.0838],\n",
      "          [-0.0709, -0.0404,  0.0303, -0.0895,  0.0253],\n",
      "          [-0.0061, -0.0620, -0.1145, -0.0871,  0.1027],\n",
      "          [ 0.0463, -0.0492,  0.0148, -0.0602, -0.0141],\n",
      "          [-0.0611,  0.0690, -0.0509,  0.1046,  0.0481]],\n",
      "\n",
      "         [[-0.0431,  0.0583,  0.0131, -0.0762, -0.1143],\n",
      "          [-0.0858,  0.0901, -0.0965, -0.0457,  0.0184],\n",
      "          [ 0.0686,  0.0699,  0.0702, -0.0319,  0.0892],\n",
      "          [-0.0689,  0.0490,  0.0696,  0.0502,  0.1115],\n",
      "          [ 0.0084,  0.0781,  0.0595, -0.0821,  0.0628]],\n",
      "\n",
      "         [[-0.0128, -0.0996, -0.1036, -0.0053,  0.0210],\n",
      "          [-0.0064,  0.0838,  0.0748,  0.0523,  0.0474],\n",
      "          [-0.0302,  0.1143,  0.0046,  0.0959, -0.0198],\n",
      "          [ 0.0893, -0.1080, -0.1047,  0.0474, -0.0027],\n",
      "          [ 0.0705,  0.0520,  0.0225, -0.0164,  0.1151]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0526, -0.0746,  0.0987, -0.0443, -0.0427],\n",
      "          [ 0.0139, -0.0216, -0.0933,  0.0889, -0.0688],\n",
      "          [-0.1057,  0.0892,  0.0603, -0.0012,  0.1068],\n",
      "          [ 0.0088,  0.0756, -0.0431,  0.0322, -0.0681],\n",
      "          [-0.0271,  0.0611, -0.0799,  0.0192,  0.1083]],\n",
      "\n",
      "         [[-0.0139,  0.0459,  0.0943,  0.0180, -0.0992],\n",
      "          [ 0.0544, -0.0362,  0.0619, -0.0282, -0.0110],\n",
      "          [ 0.0300,  0.0330, -0.0323,  0.0868,  0.0040],\n",
      "          [-0.0549,  0.1016, -0.0265,  0.0093, -0.0369],\n",
      "          [ 0.0470, -0.0673, -0.0478,  0.0335, -0.0882]],\n",
      "\n",
      "         [[ 0.0327, -0.1065, -0.0579, -0.1135,  0.0333],\n",
      "          [ 0.0299, -0.0479, -0.0921, -0.1040,  0.0489],\n",
      "          [-0.1137, -0.0041,  0.0870, -0.0888,  0.0894],\n",
      "          [ 0.0986, -0.0796,  0.0528,  0.0758, -0.0060],\n",
      "          [ 0.0128,  0.0393, -0.0185,  0.1150,  0.0929]]],\n",
      "\n",
      "\n",
      "        [[[-0.0629, -0.0284, -0.0409, -0.0968,  0.0323],\n",
      "          [-0.0351,  0.0633, -0.0309, -0.1013, -0.1043],\n",
      "          [ 0.0057, -0.0086,  0.0351,  0.0072, -0.0119],\n",
      "          [-0.1068, -0.0496, -0.0903, -0.0026, -0.0154],\n",
      "          [ 0.0839,  0.1058, -0.0398, -0.1029, -0.0322]],\n",
      "\n",
      "         [[-0.0863,  0.0451,  0.0072, -0.0226, -0.0930],\n",
      "          [ 0.0833,  0.1101,  0.0070,  0.0821, -0.1017],\n",
      "          [ 0.0132, -0.0434, -0.0194,  0.0115,  0.0787],\n",
      "          [-0.0278,  0.0165,  0.0502,  0.0067, -0.0959],\n",
      "          [-0.0708, -0.1036,  0.0638, -0.0977, -0.0604]],\n",
      "\n",
      "         [[-0.0780,  0.0529, -0.1135,  0.0729,  0.0456],\n",
      "          [ 0.0077, -0.0600,  0.0583, -0.0680,  0.0057],\n",
      "          [ 0.0099,  0.0358, -0.0681, -0.0859,  0.0228],\n",
      "          [ 0.0137, -0.0313,  0.0558,  0.0191, -0.0198],\n",
      "          [-0.0100, -0.0373,  0.0375, -0.0255,  0.0500]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print(list(net.parameters())) # print all parameters\n",
    "print(net.conv1.weight) # print the weight of one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "print(net.conv1.weight.grad) # print grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zero the parameter gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# get one training image\n",
    "dataiter = iter(trainloader)\n",
    "image, label = dataiter.next()\n",
    "\n",
    "# forward + backward + optimize\n",
    "output = net(image)\n",
    "loss = criterion(output, label)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0073,  0.0047,  0.0033,  0.0045,  0.0036],\n",
      "          [ 0.0045,  0.0021,  0.0011,  0.0021,  0.0034],\n",
      "          [ 0.0004, -0.0010,  0.0012,  0.0017,  0.0043],\n",
      "          [-0.0026, -0.0018,  0.0017,  0.0034,  0.0056],\n",
      "          [-0.0031, -0.0038, -0.0001,  0.0028,  0.0025]],\n",
      "\n",
      "         [[ 0.0117,  0.0081,  0.0053,  0.0056,  0.0049],\n",
      "          [ 0.0079,  0.0047,  0.0037,  0.0043,  0.0056],\n",
      "          [ 0.0017,  0.0002,  0.0034,  0.0046,  0.0075],\n",
      "          [-0.0023, -0.0018,  0.0027,  0.0058,  0.0086],\n",
      "          [-0.0022, -0.0036,  0.0006,  0.0047,  0.0047]],\n",
      "\n",
      "         [[ 0.0124,  0.0086,  0.0052,  0.0052,  0.0039],\n",
      "          [ 0.0103,  0.0063,  0.0041,  0.0037,  0.0049],\n",
      "          [ 0.0037,  0.0014,  0.0041,  0.0050,  0.0084],\n",
      "          [-0.0016, -0.0016,  0.0033,  0.0080,  0.0119],\n",
      "          [-0.0008, -0.0029,  0.0018,  0.0078,  0.0088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0007,  0.0011,  0.0006, -0.0093, -0.0110],\n",
      "          [-0.0030, -0.0049, -0.0042, -0.0055, -0.0041],\n",
      "          [-0.0008, -0.0045, -0.0058, -0.0049, -0.0021],\n",
      "          [-0.0000, -0.0047, -0.0091, -0.0092, -0.0047],\n",
      "          [-0.0007, -0.0069, -0.0106, -0.0101, -0.0081]],\n",
      "\n",
      "         [[ 0.0061,  0.0059,  0.0040, -0.0058, -0.0059],\n",
      "          [ 0.0041,  0.0014,  0.0007, -0.0004,  0.0029],\n",
      "          [ 0.0065,  0.0025,  0.0003,  0.0016,  0.0066],\n",
      "          [ 0.0058,  0.0009, -0.0035, -0.0028,  0.0036],\n",
      "          [ 0.0049, -0.0021, -0.0062, -0.0050, -0.0013]],\n",
      "\n",
      "         [[ 0.0099,  0.0109,  0.0061, -0.0049, -0.0037],\n",
      "          [ 0.0087,  0.0062,  0.0021, -0.0013,  0.0032],\n",
      "          [ 0.0130,  0.0075,  0.0027,  0.0025,  0.0085],\n",
      "          [ 0.0128,  0.0072,  0.0021,  0.0024,  0.0091],\n",
      "          [ 0.0096,  0.0037,  0.0006,  0.0017,  0.0057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0001, -0.0045, -0.0011,  0.0004, -0.0004],\n",
      "          [ 0.0014, -0.0046, -0.0033,  0.0006, -0.0046],\n",
      "          [ 0.0040, -0.0023,  0.0021,  0.0011, -0.0020],\n",
      "          [ 0.0049,  0.0047,  0.0057,  0.0007, -0.0024],\n",
      "          [ 0.0013,  0.0034,  0.0022, -0.0013, -0.0022]],\n",
      "\n",
      "         [[ 0.0018, -0.0022,  0.0003,  0.0002, -0.0006],\n",
      "          [ 0.0038, -0.0019, -0.0016,  0.0020, -0.0021],\n",
      "          [ 0.0054, -0.0002,  0.0042,  0.0037,  0.0020],\n",
      "          [ 0.0070,  0.0077,  0.0091,  0.0048,  0.0018],\n",
      "          [ 0.0047,  0.0076,  0.0072,  0.0035,  0.0012]],\n",
      "\n",
      "         [[ 0.0015,  0.0000,  0.0037,  0.0025,  0.0000],\n",
      "          [ 0.0031, -0.0002,  0.0017,  0.0047,  0.0003],\n",
      "          [ 0.0070,  0.0037,  0.0080,  0.0061,  0.0047],\n",
      "          [ 0.0103,  0.0124,  0.0131,  0.0079,  0.0056],\n",
      "          [ 0.0059,  0.0091,  0.0111,  0.0088,  0.0057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0062,  0.0094,  0.0108,  0.0118,  0.0083],\n",
      "          [ 0.0080,  0.0110,  0.0117,  0.0126,  0.0076],\n",
      "          [ 0.0086,  0.0097,  0.0128,  0.0103,  0.0052],\n",
      "          [ 0.0083,  0.0071,  0.0093,  0.0083,  0.0029],\n",
      "          [ 0.0067,  0.0065,  0.0079,  0.0061,  0.0022]],\n",
      "\n",
      "         [[ 0.0033,  0.0068,  0.0090,  0.0102,  0.0063],\n",
      "          [ 0.0055,  0.0094,  0.0110,  0.0115,  0.0057],\n",
      "          [ 0.0056,  0.0079,  0.0122,  0.0094,  0.0027],\n",
      "          [ 0.0051,  0.0044,  0.0080,  0.0067, -0.0005],\n",
      "          [ 0.0042,  0.0038,  0.0054,  0.0034, -0.0020]],\n",
      "\n",
      "         [[ 0.0006,  0.0035,  0.0056,  0.0081,  0.0038],\n",
      "          [ 0.0018,  0.0060,  0.0089,  0.0101,  0.0030],\n",
      "          [ 0.0032,  0.0058,  0.0106,  0.0083,  0.0001],\n",
      "          [ 0.0026,  0.0025,  0.0061,  0.0049, -0.0037],\n",
      "          [ 0.0005,  0.0010,  0.0035,  0.0013, -0.0060]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0061,  0.0083,  0.0041,  0.0049, -0.0032],\n",
      "          [ 0.0021,  0.0009, -0.0014,  0.0041, -0.0036],\n",
      "          [-0.0019, -0.0021, -0.0005,  0.0015, -0.0053],\n",
      "          [-0.0080, -0.0045, -0.0034, -0.0064, -0.0049],\n",
      "          [-0.0104, -0.0060, -0.0068, -0.0077,  0.0018]],\n",
      "\n",
      "         [[ 0.0090,  0.0120,  0.0091,  0.0109,  0.0029],\n",
      "          [ 0.0045,  0.0038,  0.0030,  0.0109,  0.0037],\n",
      "          [ 0.0000, -0.0009,  0.0029,  0.0086,  0.0029],\n",
      "          [-0.0063, -0.0038, -0.0007, -0.0009,  0.0010],\n",
      "          [-0.0097, -0.0046, -0.0033, -0.0035,  0.0054]],\n",
      "\n",
      "         [[ 0.0118,  0.0143,  0.0137,  0.0166,  0.0097],\n",
      "          [ 0.0076,  0.0065,  0.0067,  0.0164,  0.0105],\n",
      "          [ 0.0026, -0.0006,  0.0032,  0.0122,  0.0074],\n",
      "          [-0.0052, -0.0046,  0.0005,  0.0044,  0.0062],\n",
      "          [-0.0101, -0.0049, -0.0009,  0.0011,  0.0092]]],\n",
      "\n",
      "\n",
      "        [[[-0.0031,  0.0002, -0.0007, -0.0042, -0.0023],\n",
      "          [-0.0010,  0.0039,  0.0021, -0.0018, -0.0054],\n",
      "          [ 0.0006,  0.0023,  0.0015, -0.0000, -0.0057],\n",
      "          [ 0.0011, -0.0007,  0.0025,  0.0046,  0.0028],\n",
      "          [ 0.0021,  0.0005,  0.0026,  0.0064,  0.0096]],\n",
      "\n",
      "         [[-0.0082, -0.0051, -0.0046, -0.0070, -0.0057],\n",
      "          [-0.0066, -0.0027, -0.0037, -0.0058, -0.0086],\n",
      "          [-0.0067, -0.0064, -0.0070, -0.0064, -0.0104],\n",
      "          [-0.0062, -0.0084, -0.0047, -0.0014, -0.0019],\n",
      "          [-0.0042, -0.0053, -0.0024,  0.0017,  0.0049]],\n",
      "\n",
      "         [[-0.0130, -0.0098, -0.0104, -0.0126, -0.0114],\n",
      "          [-0.0116, -0.0085, -0.0100, -0.0112, -0.0135],\n",
      "          [-0.0132, -0.0134, -0.0122, -0.0105, -0.0134],\n",
      "          [-0.0127, -0.0139, -0.0088, -0.0053, -0.0051],\n",
      "          [-0.0097, -0.0095, -0.0055, -0.0017,  0.0017]]]])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
